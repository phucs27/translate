{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>classID</th>\n",
       "      <th>relative_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enoutput_02024_10_07_22_49_51_552246.wav</td>\n",
       "      <td>fold_en</td>\n",
       "      <td>2</td>\n",
       "      <td>/fold_en/enoutput_02024_10_07_22_49_51_552246.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enoutput_10002024_10_07_22_49_51_552246.wav</td>\n",
       "      <td>fold_en</td>\n",
       "      <td>2</td>\n",
       "      <td>/fold_en/enoutput_10002024_10_07_22_49_51_5522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enoutput_1002024_10_07_22_49_51_552246.wav</td>\n",
       "      <td>fold_en</td>\n",
       "      <td>2</td>\n",
       "      <td>/fold_en/enoutput_1002024_10_07_22_49_51_55224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enoutput_10052024_10_07_22_49_51_552246.wav</td>\n",
       "      <td>fold_en</td>\n",
       "      <td>2</td>\n",
       "      <td>/fold_en/enoutput_10052024_10_07_22_49_51_5522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enoutput_10102024_10_07_22_49_51_552246.wav</td>\n",
       "      <td>fold_en</td>\n",
       "      <td>2</td>\n",
       "      <td>/fold_en/enoutput_10102024_10_07_22_49_51_5522...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Filename    Label  classID  \\\n",
       "0     enoutput_02024_10_07_22_49_51_552246.wav  fold_en        2   \n",
       "1  enoutput_10002024_10_07_22_49_51_552246.wav  fold_en        2   \n",
       "2   enoutput_1002024_10_07_22_49_51_552246.wav  fold_en        2   \n",
       "3  enoutput_10052024_10_07_22_49_51_552246.wav  fold_en        2   \n",
       "4  enoutput_10102024_10_07_22_49_51_552246.wav  fold_en        2   \n",
       "\n",
       "                                       relative_path  \n",
       "0  /fold_en/enoutput_02024_10_07_22_49_51_552246.wav  \n",
       "1  /fold_en/enoutput_10002024_10_07_22_49_51_5522...  \n",
       "2  /fold_en/enoutput_1002024_10_07_22_49_51_55224...  \n",
       "3  /fold_en/enoutput_10052024_10_07_22_49_51_5522...  \n",
       "4  /fold_en/enoutput_10102024_10_07_22_49_51_5522...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Prepare training data from Metadata file\n",
    "# ----------------------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = r'D:\\0_Workplace\\Project_Python\\audio_process\\data\\train'\n",
    "\n",
    "# Read metadata file\n",
    "metadata_file = r\"D:\\0_Workplace\\Project_Python\\audio_process\\data\\train\\audio_labels2.csv\"\n",
    "df = pd.read_csv(metadata_file)\n",
    "df.head()\n",
    "\n",
    "# Construct file path by concatenating fold and file name\n",
    "df['relative_path'] = '/'+df['Label'].astype(str) + '/' + df['Filename'].astype(str)\n",
    "\n",
    "# Take relevant columns\n",
    "# df = df[['relative_path', 'classID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from dataset import SoundDS\n",
    "import torch\n",
    "\n",
    "myds = SoundDS(df, data_path)\n",
    "\n",
    "# Random split of 80:20 between training and validation\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from audioclassifier import AudioClassifier\n",
    "# Create the model and put it on the GPU if available\n",
    "model = nn.DataParallel(AudioClassifier())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "# Check that it is on Cuda\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "import torch.utils\n",
    "import torch.utils.tensorboard\n",
    "\n",
    "\n",
    "def training(model, train_dl, num_epochs):\n",
    "    # Tensorboard\n",
    "    writer = torch.utils.tensorboard.SummaryWriter()\n",
    "    # Loss Function, Optimizer and Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            print(data)\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[2].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "            #if i % 10 == 0:    # print every 10 mini-batches\n",
    "            #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "        \n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        avg_acc = correct_prediction/total_prediction\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        writer.add_scalar(\"Acc/train\", avg_acc, epoch)\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {avg_acc:.2f}')\n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "    print('Finished Training')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 20.9928,  -3.7563, -11.4807,  ...,  16.5229,  11.1248,  10.3414],\n",
      "          [ 21.4776,  -1.2614,  -4.3272,  ...,  12.3113,   2.1380,   3.9434],\n",
      "          [ 26.0693,  15.7920,  19.4872,  ...,   5.6844, -12.8872,   6.8701],\n",
      "          ...,\n",
      "          [-39.5577, -39.5577, -37.6804,  ..., -39.5577, -39.5577, -39.5577],\n",
      "          [-39.5577, -39.5577, -39.5577,  ..., -39.5577, -39.5577, -39.5577],\n",
      "          [-39.5577, -39.5577, -39.5577,  ..., -39.5577, -39.5577, -39.5577]],\n",
      "\n",
      "         [[ 20.9928,  -3.7563, -11.4807,  ...,  16.5229,  11.1248,  10.3414],\n",
      "          [ 21.4776,  -1.2614,  -4.3272,  ...,  12.3113,   2.1380,   3.9434],\n",
      "          [ 26.0693,  15.7920,  19.4872,  ...,   5.6844, -12.8872,   6.8701],\n",
      "          ...,\n",
      "          [-39.5577, -39.5577, -37.6804,  ..., -39.5577, -39.5577, -39.5577],\n",
      "          [-39.5577, -39.5577, -39.5577,  ..., -39.5577, -39.5577, -39.5577],\n",
      "          [-39.5577, -39.5577, -39.5577,  ..., -39.5577, -39.5577, -39.5577]]],\n",
      "\n",
      "\n",
      "        [[[ 11.6899,  -0.1726,   0.2820,  ...,   8.5669,  -0.1893,   4.9085],\n",
      "          [  3.8566,   7.5587,   2.5340,  ...,   6.1567,  15.8232,   5.2352],\n",
      "          [ 23.3890,  21.5491,  22.7438,  ...,   8.7001,  17.4101,  21.7985],\n",
      "          ...,\n",
      "          [ -7.6977,  -7.6977,  -7.6977,  ...,  -7.6977,  -7.6977,  -7.6977],\n",
      "          [-40.4240, -40.4240, -40.4240,  ..., -40.4240, -40.4240, -40.4240],\n",
      "          [-40.4240, -40.4240, -40.4240,  ..., -40.4240, -40.4240, -40.4240]],\n",
      "\n",
      "         [[ 11.6899,  -0.1726,   0.2820,  ...,   8.5669,  -0.1893,   4.9091],\n",
      "          [  3.8566,   7.5587,   2.5340,  ...,   6.1567,  15.8232,   5.2358],\n",
      "          [ 23.3890,  21.5491,  22.7438,  ...,   8.7001,  17.4101,  21.7987],\n",
      "          ...,\n",
      "          [ -7.6977,  -7.6977,  -7.6977,  ...,  -7.6977,  -7.6977,  -7.6977],\n",
      "          [-40.4240, -40.4240, -40.4240,  ..., -40.4240, -40.4240, -40.4240],\n",
      "          [-40.4240, -40.4240, -40.4240,  ..., -40.4240, -40.4240, -40.4240]]],\n",
      "\n",
      "\n",
      "        [[[-15.7273, -15.7273, -15.7273,  ..., -15.7273, -15.7273, -15.7273],\n",
      "          [-15.7273, -15.7273, -15.7273,  ..., -15.7273, -15.7273, -15.7273],\n",
      "          [-15.7273, -15.7273, -15.7273,  ..., -15.7273, -15.7273, -15.7273],\n",
      "          ...,\n",
      "          [-42.2131, -42.2131, -42.2131,  ..., -42.2131, -42.2131, -42.2131],\n",
      "          [-42.2131, -42.2131, -42.2131,  ..., -42.2131, -42.2131, -42.2131],\n",
      "          [-42.2131, -42.2131, -42.2131,  ..., -42.2131, -42.2131, -42.2131]],\n",
      "\n",
      "         [[-15.7273, -15.7273, -15.7273,  ..., -15.7273, -15.7273, -15.7273],\n",
      "          [-15.7273, -15.7273, -15.7273,  ..., -15.7273, -15.7273, -15.7273],\n",
      "          [-15.7273, -15.7273, -15.7273,  ..., -15.7273, -15.7273, -15.7273],\n",
      "          ...,\n",
      "          [-42.2131, -42.2131, -42.2131,  ..., -42.2131, -42.2131, -42.2131],\n",
      "          [-42.2131, -42.2131, -42.2131,  ..., -42.2131, -42.2131, -42.2131],\n",
      "          [-42.2131, -42.2131, -42.2131,  ..., -42.2131, -42.2131, -42.2131]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[  5.5170,   2.0061,  -6.0504,  ...,   2.2104, -24.7936,  -5.3579],\n",
      "          [ -3.4712,  -4.5262,  -7.9349,  ...,  -6.6494, -13.3907,  -9.6892],\n",
      "          [-11.3861,  -7.2538, -10.9759,  ..., -10.3637,  -8.4169, -13.1906],\n",
      "          ...,\n",
      "          [-40.6109, -40.6109, -40.6109,  ..., -40.6109, -40.6109, -40.6109],\n",
      "          [-40.6109, -40.6109, -40.6109,  ..., -40.6109, -40.6109, -40.6109],\n",
      "          [-40.6109, -40.6109, -40.6109,  ..., -40.6109, -40.6109, -40.6109]],\n",
      "\n",
      "         [[  5.5170,   2.0061,  -6.0504,  ...,   2.2104, -24.7936,  -5.3579],\n",
      "          [ -3.4712,  -4.5262,  -7.9349,  ...,  -6.6494, -13.3907,  -9.6892],\n",
      "          [-11.3861,  -7.2538, -10.9759,  ..., -10.3637,  -8.4169, -13.1906],\n",
      "          ...,\n",
      "          [-40.6109, -40.6109, -40.6109,  ..., -40.6109, -40.6109, -40.6109],\n",
      "          [-40.6109, -40.6109, -40.6109,  ..., -40.6109, -40.6109, -40.6109],\n",
      "          [-40.6109, -40.6109, -40.6109,  ..., -40.6109, -40.6109, -40.6109]]],\n",
      "\n",
      "\n",
      "        [[[  2.2341,   6.6823,   9.7104,  ...,   3.3611,  11.0895,  -0.6237],\n",
      "          [ -5.0194,   1.9160,   1.3399,  ...,  -5.1578,   3.3694,  -5.8164],\n",
      "          [-16.0965, -16.0965, -16.0965,  ..., -16.0965, -16.0965, -16.0965],\n",
      "          ...,\n",
      "          [-39.8487, -39.8487, -39.8487,  ..., -39.8487, -39.8487, -39.8487],\n",
      "          [-39.8487, -39.8487, -39.8487,  ..., -39.8487, -39.8487, -39.8487],\n",
      "          [-39.8487, -39.8487, -39.8487,  ..., -39.8487, -39.8487, -39.8487]],\n",
      "\n",
      "         [[  2.2341,   6.6823,   9.7104,  ...,   3.3611,  11.0895,  -0.6237],\n",
      "          [ -5.0194,   1.9160,   1.3399,  ...,  -5.1578,   3.3694,  -5.8164],\n",
      "          [-16.0965, -16.0965, -16.0965,  ..., -16.0965, -16.0965, -16.0965],\n",
      "          ...,\n",
      "          [-39.8487, -39.8487, -39.8487,  ..., -39.8487, -39.8487, -39.8487],\n",
      "          [-39.8487, -39.8487, -39.8487,  ..., -39.8487, -39.8487, -39.8487],\n",
      "          [-39.8487, -39.8487, -39.8487,  ..., -39.8487, -39.8487, -39.8487]]],\n",
      "\n",
      "\n",
      "        [[[-34.4386,   1.7726,   2.9352,  ..., -11.9983,  -9.5463,  -7.9333],\n",
      "          [ -1.4823,   4.7159,   8.7490,  ..., -16.8074, -13.6223, -11.2278],\n",
      "          [ -8.3351,   7.5594,  19.0263,  ..., -22.1705,  -9.8535,  -8.6476],\n",
      "          ...,\n",
      "          [-35.2000, -35.2000, -35.2000,  ..., -35.2000, -35.2000, -35.2000],\n",
      "          [-35.2000, -35.2000, -35.2000,  ..., -35.2000, -35.2000, -35.2000],\n",
      "          [-35.2000, -35.2000, -35.2000,  ..., -35.2000, -35.2000, -35.2000]],\n",
      "\n",
      "         [[ -7.6926,   3.2921,   2.1861,  ..., -18.4420, -10.3339,  -9.3634],\n",
      "          [ -1.9229,   4.8598,   9.0029,  ..., -19.6341, -11.0283,  -9.5542],\n",
      "          [ -6.3843,   5.5999,  19.3828,  ..., -14.8195, -13.2807,  -7.0535],\n",
      "          ...,\n",
      "          [-35.2000, -35.2000, -35.2000,  ..., -35.1115, -35.2000, -35.2000],\n",
      "          [-35.2000, -35.2000, -35.2000,  ..., -35.2000, -35.2000, -35.2000],\n",
      "          [-35.2000, -35.2000, -35.2000,  ..., -35.2000, -35.2000, -35.2000]]]]), ('fold_en', 'fold_en', 'fold_ko', 'fold_en', 'fold_ko', 'fold_vi', 'fold_ko', 'fold_en', 'fold_en', 'fold_en', 'fold_ko', 'fold_vi', 'fold_ko', 'fold_ko', 'fold_ko', 'fold_vi')]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[73], line 29\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, train_dl, num_epochs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[0;32m     28\u001b[0m inputs \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 29\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Normalize the inputs\u001b[39;00m\n\u001b[0;32m     32\u001b[0m inputs_m, inputs_s \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mmean(), inputs\u001b[38;5;241m.\u001b[39mstd()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "num_epochs=2\n",
    "training(model, train_dl, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
